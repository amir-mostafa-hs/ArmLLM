{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fx0kljkq5b2i",
        "outputId": "1d8c290c-dfca-4700-9012-fd7487e8de62"
      },
      "outputs": [],
      "source": [
        "# Check runtime type\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "if shutil.which(\"nvidia-smi\") is None:\n",
        "    print(\"⚠️ GPU is not active.  Please select GPU from Runtime> Change Runtime Type.\")\n",
        "else:\n",
        "    gpu_info = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode()\n",
        "    if \"T4\" in gpu_info:\n",
        "        print(\"✅ T4 GPU Active.\")\n",
        "    else:\n",
        "        print(\"⚠️ GPU It is active but not T4.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u1nj_B0h6FqT",
        "outputId": "d4e1556e-f415-447b-83d5-eace8326c987"
      },
      "outputs": [],
      "source": [
        "# Clone repository.\n",
        "!git clone https://github.com/osoblanco/ArmLLM.git\n",
        "%cd ArmLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2e9df1a7",
        "outputId": "9cba048d-f13b-483c-b4c9-73b8b4bcef80"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install Mamba using Miniforge\n",
        "!wget -q https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh -O miniforge.sh\n",
        "!bash miniforge.sh -b -p /opt/conda\n",
        "!rm miniforge.sh\n",
        "\n",
        "# Step 2: Add conda/mamba to PATH\n",
        "import os\n",
        "os.environ['PATH'] = '/opt/conda/bin:' + os.environ['PATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pvDezSqw7r3D",
        "outputId": "6fa22e11-5181-4428-8613-9b4c5975ecf1"
      },
      "outputs": [],
      "source": [
        "# Step 3: Create a new environment with mamba and activate it\n",
        "!conda install -y mamba -n base -c conda-forge\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3mgojRyt73_o",
        "outputId": "c428ce83-aa21-4ae3-849b-4c079918ff37"
      },
      "outputs": [],
      "source": [
        "# Step 4: Install packages using mamba\n",
        "!mamba install -c pytorch -c nvidia pytorch torchvision torchaudio pytorch-cuda=12.1 htop ncdu tmate nvtop s5cmd -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d686a19c",
        "outputId": "bb024081-7aed-4ad3-9623-98a67df044f7"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers tqdm py-spy jupyter streamlit plotly pyinstrument tokenizers cached_path accelerate bitsandbytes trl vllm"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
